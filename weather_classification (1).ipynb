{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d459690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# for Classifcation\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, \\\n",
    "    precision_recall_fscore_support,precision_score,recall_score,classification_report\n",
    "# for Regression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,\\\n",
    "explained_variance_score, max_error, median_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "#from pycaret.regression import *\n",
    "from pycaret.classification import *\n",
    "#from pycaret.clustering import *\n",
    "from skimpy import skim\n",
    "from summarytools import dfSummary\n",
    "import sweetviz as sv\n",
    "import statsmodels.api as sm\n",
    "import missingno as msno\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"dask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e8c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"E:\\Machine Project\\Cleand_weather_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b0df25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>minimum_temp</th>\n",
       "      <th>maximum_temp</th>\n",
       "      <th>rain_fall</th>\n",
       "      <th>Wind_gustspeed</th>\n",
       "      <th>Winddir_9am</th>\n",
       "      <th>Winddir_3pm</th>\n",
       "      <th>Wind_speed9am</th>\n",
       "      <th>Wind_speed3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity_3pm</th>\n",
       "      <th>Pressure_9am</th>\n",
       "      <th>Pressure_3pm</th>\n",
       "      <th>Cloud_9am</th>\n",
       "      <th>cloud3pm</th>\n",
       "      <th>Temp_9am</th>\n",
       "      <th>Temp_3pm</th>\n",
       "      <th>Rain_today</th>\n",
       "      <th>risk_mm</th>\n",
       "      <th>Rain_tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.40</td>\n",
       "      <td>22.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>44.00</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>20.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>...</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1007.70</td>\n",
       "      <td>1007.10</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.90</td>\n",
       "      <td>21.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.40</td>\n",
       "      <td>25.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>4.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>...</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1010.60</td>\n",
       "      <td>1007.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17.20</td>\n",
       "      <td>24.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.90</td>\n",
       "      <td>25.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>19.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>...</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1007.60</td>\n",
       "      <td>1008.70</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>23.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.20</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>11.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>16.00</td>\n",
       "      <td>1017.60</td>\n",
       "      <td>1012.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.10</td>\n",
       "      <td>26.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.50</td>\n",
       "      <td>32.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>7.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>...</td>\n",
       "      <td>33.00</td>\n",
       "      <td>1010.80</td>\n",
       "      <td>1006.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>17.80</td>\n",
       "      <td>29.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008-12-06</td>\n",
       "      <td>Albury</td>\n",
       "      <td>14.60</td>\n",
       "      <td>29.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>56.00</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>19.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>...</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1009.20</td>\n",
       "      <td>1005.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.60</td>\n",
       "      <td>28.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008-12-07</td>\n",
       "      <td>Albury</td>\n",
       "      <td>14.30</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>SW</td>\n",
       "      <td>W</td>\n",
       "      <td>20.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>...</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1009.60</td>\n",
       "      <td>1008.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.10</td>\n",
       "      <td>24.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008-12-08</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.70</td>\n",
       "      <td>26.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>SSE</td>\n",
       "      <td>W</td>\n",
       "      <td>6.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>...</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1013.40</td>\n",
       "      <td>1010.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.30</td>\n",
       "      <td>25.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008-12-09</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.70</td>\n",
       "      <td>31.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.84</td>\n",
       "      <td>SE</td>\n",
       "      <td>NW</td>\n",
       "      <td>7.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1008.90</td>\n",
       "      <td>1003.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.30</td>\n",
       "      <td>30.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008-12-10</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.10</td>\n",
       "      <td>30.10</td>\n",
       "      <td>1.40</td>\n",
       "      <td>28.00</td>\n",
       "      <td>S</td>\n",
       "      <td>SSE</td>\n",
       "      <td>15.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>...</td>\n",
       "      <td>27.00</td>\n",
       "      <td>1007.00</td>\n",
       "      <td>1005.70</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.10</td>\n",
       "      <td>28.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2008-12-11</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.40</td>\n",
       "      <td>30.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>SSE</td>\n",
       "      <td>ESE</td>\n",
       "      <td>17.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>...</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1011.80</td>\n",
       "      <td>1008.70</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.40</td>\n",
       "      <td>28.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2008-12-12</td>\n",
       "      <td>Albury</td>\n",
       "      <td>15.90</td>\n",
       "      <td>21.70</td>\n",
       "      <td>2.64</td>\n",
       "      <td>31.00</td>\n",
       "      <td>NE</td>\n",
       "      <td>ENE</td>\n",
       "      <td>15.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>...</td>\n",
       "      <td>91.00</td>\n",
       "      <td>1010.50</td>\n",
       "      <td>1004.20</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>15.90</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008-12-13</td>\n",
       "      <td>Albury</td>\n",
       "      <td>15.90</td>\n",
       "      <td>18.60</td>\n",
       "      <td>2.64</td>\n",
       "      <td>61.00</td>\n",
       "      <td>NNW</td>\n",
       "      <td>NNW</td>\n",
       "      <td>28.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>...</td>\n",
       "      <td>93.00</td>\n",
       "      <td>1018.39</td>\n",
       "      <td>1015.54</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>17.40</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2008-12-14</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.60</td>\n",
       "      <td>21.00</td>\n",
       "      <td>2.64</td>\n",
       "      <td>44.00</td>\n",
       "      <td>W</td>\n",
       "      <td>SSW</td>\n",
       "      <td>24.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>...</td>\n",
       "      <td>43.00</td>\n",
       "      <td>1018.39</td>\n",
       "      <td>1015.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>15.80</td>\n",
       "      <td>19.80</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2008-12-16</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.80</td>\n",
       "      <td>27.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>SW</td>\n",
       "      <td>WNW</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>...</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1013.40</td>\n",
       "      <td>1010.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17.30</td>\n",
       "      <td>26.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2008-12-17</td>\n",
       "      <td>Albury</td>\n",
       "      <td>14.10</td>\n",
       "      <td>20.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>SSW</td>\n",
       "      <td>E</td>\n",
       "      <td>11.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>82.00</td>\n",
       "      <td>1012.20</td>\n",
       "      <td>1010.40</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17.20</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2008-12-18</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.50</td>\n",
       "      <td>22.90</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.84</td>\n",
       "      <td>N</td>\n",
       "      <td>WNW</td>\n",
       "      <td>6.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>...</td>\n",
       "      <td>65.00</td>\n",
       "      <td>1005.80</td>\n",
       "      <td>1015.54</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008-12-19</td>\n",
       "      <td>Albury</td>\n",
       "      <td>11.20</td>\n",
       "      <td>22.50</td>\n",
       "      <td>2.64</td>\n",
       "      <td>43.00</td>\n",
       "      <td>WSW</td>\n",
       "      <td>SW</td>\n",
       "      <td>24.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>...</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1009.40</td>\n",
       "      <td>1009.70</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>15.50</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2008-12-20</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.80</td>\n",
       "      <td>25.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>SE</td>\n",
       "      <td>NNW</td>\n",
       "      <td>17.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>...</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1019.20</td>\n",
       "      <td>1017.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.80</td>\n",
       "      <td>23.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2008-12-21</td>\n",
       "      <td>Albury</td>\n",
       "      <td>11.50</td>\n",
       "      <td>29.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>SE</td>\n",
       "      <td>SE</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1019.30</td>\n",
       "      <td>1014.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.10</td>\n",
       "      <td>27.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date location  minimum_temp  maximum_temp  rain_fall  \\\n",
       "0   2008-12-01   Albury         13.40         22.90       0.60   \n",
       "1   2008-12-02   Albury          7.40         25.10       0.00   \n",
       "2   2008-12-03   Albury         12.90         25.70       0.00   \n",
       "3   2008-12-04   Albury          9.20         28.00       0.00   \n",
       "4   2008-12-05   Albury         17.50         32.30       1.00   \n",
       "5   2008-12-06   Albury         14.60         29.70       0.20   \n",
       "6   2008-12-07   Albury         14.30         25.00       0.00   \n",
       "7   2008-12-08   Albury          7.70         26.70       0.00   \n",
       "8   2008-12-09   Albury          9.70         31.90       0.00   \n",
       "9   2008-12-10   Albury         13.10         30.10       1.40   \n",
       "10  2008-12-11   Albury         13.40         30.40       0.00   \n",
       "11  2008-12-12   Albury         15.90         21.70       2.64   \n",
       "12  2008-12-13   Albury         15.90         18.60       2.64   \n",
       "13  2008-12-14   Albury         12.60         21.00       2.64   \n",
       "14  2008-12-16   Albury          9.80         27.70       0.00   \n",
       "15  2008-12-17   Albury         14.10         20.90       0.00   \n",
       "16  2008-12-18   Albury         13.50         22.90       2.64   \n",
       "17  2008-12-19   Albury         11.20         22.50       2.64   \n",
       "18  2008-12-20   Albury          9.80         25.60       0.00   \n",
       "19  2008-12-21   Albury         11.50         29.30       0.00   \n",
       "\n",
       "    Wind_gustspeed Winddir_9am Winddir_3pm  Wind_speed9am  Wind_speed3pm  ...  \\\n",
       "0            44.00           W         WNW          20.00          24.00  ...   \n",
       "1            44.00         NNW         WSW           4.00          22.00  ...   \n",
       "2            46.00           W         WSW          19.00          26.00  ...   \n",
       "3            24.00          SE           E          11.00           9.00  ...   \n",
       "4            41.00         ENE          NW           7.00          20.00  ...   \n",
       "5            56.00           W           W          19.00          24.00  ...   \n",
       "6            50.00          SW           W          20.00          24.00  ...   \n",
       "7            35.00         SSE           W           6.00          17.00  ...   \n",
       "8            36.84          SE          NW           7.00          28.00  ...   \n",
       "9            28.00           S         SSE          15.00          11.00  ...   \n",
       "10           30.00         SSE         ESE          17.00           6.00  ...   \n",
       "11           31.00          NE         ENE          15.00          13.00  ...   \n",
       "12           61.00         NNW         NNW          28.00          28.00  ...   \n",
       "13           44.00           W         SSW          24.00          20.00  ...   \n",
       "14           50.00          SW         WNW           0.00          22.00  ...   \n",
       "15           22.00         SSW           E          11.00           9.00  ...   \n",
       "16           36.84           N         WNW           6.00          20.00  ...   \n",
       "17           43.00         WSW          SW          24.00          17.00  ...   \n",
       "18           26.00          SE         NNW          17.00           6.00  ...   \n",
       "19           24.00          SE          SE           9.00           9.00  ...   \n",
       "\n",
       "    Humidity_3pm  Pressure_9am  Pressure_3pm  Cloud_9am  cloud3pm  Temp_9am  \\\n",
       "0          22.00       1007.70       1007.10       8.00      1.00     16.90   \n",
       "1          25.00       1010.60       1007.80       1.00      1.00     17.20   \n",
       "2          30.00       1007.60       1008.70       1.00      2.00     21.00   \n",
       "3          16.00       1017.60       1012.80       1.00      1.00     18.10   \n",
       "4          33.00       1010.80       1006.00       7.00      8.00     17.80   \n",
       "5          23.00       1009.20       1005.40       1.00      1.00     20.60   \n",
       "6          19.00       1009.60       1008.20       1.00      1.00     18.10   \n",
       "7          19.00       1013.40       1010.10       1.00      1.00     16.30   \n",
       "8           9.00       1008.90       1003.60       1.00      1.00     18.30   \n",
       "9          27.00       1007.00       1005.70       1.00      1.00     20.10   \n",
       "10         22.00       1011.80       1008.70       1.00      1.00     20.40   \n",
       "11         91.00       1010.50       1004.20       8.00      8.00     15.90   \n",
       "12         93.00       1018.39       1015.54       8.00      8.00     17.40   \n",
       "13         43.00       1018.39       1015.54       1.00      7.00     15.80   \n",
       "14         28.00       1013.40       1010.30       0.00      1.00     17.30   \n",
       "15         82.00       1012.20       1010.40       8.00      1.00     17.20   \n",
       "16         65.00       1005.80       1015.54       8.00      1.00     18.00   \n",
       "17         32.00       1009.40       1009.70       1.00      2.00     15.50   \n",
       "18         26.00       1019.20       1017.10       1.00      1.00     15.80   \n",
       "19         28.00       1019.30       1014.80       1.00      1.00     19.10   \n",
       "\n",
       "    Temp_3pm  Rain_today  risk_mm  Rain_tomorrow  \n",
       "0      21.80        0.00     0.00           0.00  \n",
       "1      24.30        0.00     0.00           0.00  \n",
       "2      23.20        0.00     0.00           0.00  \n",
       "3      26.50        0.00     1.00           0.00  \n",
       "4      29.70        0.00     0.20           0.00  \n",
       "5      28.90        0.00     0.00           0.00  \n",
       "6      24.60        0.00     0.00           0.00  \n",
       "7      25.50        0.00     0.00           0.00  \n",
       "8      30.20        0.00     1.40           0.22  \n",
       "9      28.20        0.22     0.00           0.00  \n",
       "10     28.80        0.00     2.68           0.22  \n",
       "11     17.00        0.22     2.68           0.22  \n",
       "12     15.80        0.22     2.68           0.22  \n",
       "13     19.80        0.22     0.00           0.00  \n",
       "14     26.20        0.00     0.00           0.00  \n",
       "15     18.10        0.00     2.68           0.22  \n",
       "16     21.50        0.22     2.68           0.22  \n",
       "17     21.00        0.22     0.00           0.00  \n",
       "18     23.20        0.00     0.00           0.00  \n",
       "19     27.30        0.00     0.00           0.00  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4815e85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              0\n",
       "location          0\n",
       "minimum_temp      0\n",
       "maximum_temp      0\n",
       "rain_fall         0\n",
       "Wind_gustspeed    0\n",
       "Winddir_9am       0\n",
       "Winddir_3pm       0\n",
       "Wind_speed9am     0\n",
       "Wind_speed3pm     0\n",
       "Humidity_9am      0\n",
       "Humidity_3pm      0\n",
       "Pressure_9am      0\n",
       "Pressure_3pm      0\n",
       "Cloud_9am         0\n",
       "cloud3pm          0\n",
       "Temp_9am          0\n",
       "Temp_3pm          0\n",
       "Rain_today        0\n",
       "risk_mm           0\n",
       "Rain_tomorrow     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418ae598",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b26df754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20500d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Rain_tomorrow\", axis=1)\n",
    "y = df[\"Rain_tomorrow\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de7ceea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = [\"location\", \"Winddir_9am\", \"Winddir_3pm\",\"date\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79b69ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    X[col] = label_encoder.fit_transform(X[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b1728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a6b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c68b472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for RandomForest:\n",
      "Accuracy: 0.9998\n",
      "Confusion Matrix:\n",
      "[[3889    0]\n",
      " [   1 1110]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3889\n",
      "           1       1.00      1.00      1.00      1111\n",
      "\n",
      "    accuracy                           1.00      5000\n",
      "   macro avg       1.00      1.00      1.00      5000\n",
      "weighted avg       1.00      1.00      1.00      5000\n",
      "\n",
      "\n",
      "Results for DecisionTree:\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[3889    0]\n",
      " [   0 1111]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3889\n",
      "           1       1.00      1.00      1.00      1111\n",
      "\n",
      "    accuracy                           1.00      5000\n",
      "   macro avg       1.00      1.00      1.00      5000\n",
      "weighted avg       1.00      1.00      1.00      5000\n",
      "\n",
      "\n",
      "Results for LogisticRegression:\n",
      "Accuracy: 0.946\n",
      "Confusion Matrix:\n",
      "[[3756  133]\n",
      " [ 137  974]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      3889\n",
      "           1       0.88      0.88      0.88      1111\n",
      "\n",
      "    accuracy                           0.95      5000\n",
      "   macro avg       0.92      0.92      0.92      5000\n",
      "weighted avg       0.95      0.95      0.95      5000\n",
      "\n",
      "\n",
      "Results for SVM:\n",
      "Accuracy: 0.7778\n",
      "Confusion Matrix:\n",
      "[[3889    0]\n",
      " [1111    0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      3889\n",
      "           1       0.00      0.00      0.00      1111\n",
      "\n",
      "    accuracy                           0.78      5000\n",
      "   macro avg       0.39      0.50      0.44      5000\n",
      "weighted avg       0.60      0.78      0.68      5000\n",
      "\n",
      "\n",
      "Results for KNN:\n",
      "Accuracy: 0.8224\n",
      "Confusion Matrix:\n",
      "[[3657  232]\n",
      " [ 656  455]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      3889\n",
      "           1       0.66      0.41      0.51      1111\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.76      0.67      0.70      5000\n",
      "weighted avg       0.81      0.82      0.81      5000\n",
      "\n",
      "\n",
      "Results for GradientBoosting:\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[3889    0]\n",
      " [   0 1111]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3889\n",
      "           1       1.00      1.00      1.00      1111\n",
      "\n",
      "    accuracy                           1.00      5000\n",
      "   macro avg       1.00      1.00      1.00      5000\n",
      "weighted avg       1.00      1.00      1.00      5000\n",
      "\n",
      "\n",
      "Results for NaiveBayes:\n",
      "Accuracy: 0.9814\n",
      "Confusion Matrix:\n",
      "[[3796   93]\n",
      " [   0 1111]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3889\n",
      "           1       0.92      1.00      0.96      1111\n",
      "\n",
      "    accuracy                           0.98      5000\n",
      "   macro avg       0.96      0.99      0.97      5000\n",
      "weighted avg       0.98      0.98      0.98      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'NaiveBayes': GaussianNB()\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Label encoding for the target variable\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train_encoded)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(label_encoder.transform(y_test), y_pred)\n",
    "    conf_matrix = confusion_matrix(label_encoder.transform(y_test), y_pred)\n",
    "    class_report = classification_report(label_encoder.transform(y_test), y_pred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"\\nResults for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"Classification Report:\\n{class_report}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac989159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overfitting(model, X_train, y_train, X_test, y_test, cv=5):\n",
    "    # Calculate training accuracy using cross-validation\n",
    "    train_accuracy = np.mean(cross_val_score(model, X_train, y_train, cv=cv))\n",
    "    \n",
    "    # Fit the model to the entire training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate testing accuracy\n",
    "    test_accuracy = model.score(X_test, label_encoder.transform(y_test))\n",
    "    \n",
    "    print(f\"Training Accuracy: {train_accuracy}\")\n",
    "    print(f\"Testing Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    # Compare training and testing accuracy\n",
    "    if train_accuracy > test_accuracy:\n",
    "        print(\"Risk of Overfitting: Training accuracy is higher than testing accuracy.\")\n",
    "    elif train_accuracy < test_accuracy:\n",
    "        print(\"Risk of Underfitting: Training accuracy is lower than testing accuracy.\")\n",
    "    else:\n",
    "        print(\"The model is well-fit.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f81e607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for RandomForest:\n",
      "Training Accuracy: 0.9999500000000001\n",
      "Testing Accuracy: 0.9998\n",
      "Risk of Overfitting: Training accuracy is higher than testing accuracy.\n",
      "\n",
      "Results for DecisionTree:\n",
      "Training Accuracy: 0.9999500000000001\n",
      "Testing Accuracy: 1.0\n",
      "Risk of Underfitting: Training accuracy is lower than testing accuracy.\n",
      "\n",
      "Results for LogisticRegression:\n",
      "Training Accuracy: 0.9368000000000001\n",
      "Testing Accuracy: 0.946\n",
      "Risk of Underfitting: Training accuracy is lower than testing accuracy.\n",
      "\n",
      "Results for SVM:\n",
      "Training Accuracy: 0.7758\n",
      "Testing Accuracy: 0.7778\n",
      "Risk of Underfitting: Training accuracy is lower than testing accuracy.\n",
      "\n",
      "Results for KNN:\n",
      "Training Accuracy: 0.82455\n",
      "Testing Accuracy: 0.8224\n",
      "Risk of Overfitting: Training accuracy is higher than testing accuracy.\n",
      "\n",
      "Results for GradientBoosting:\n",
      "Training Accuracy: 0.9999500000000001\n",
      "Testing Accuracy: 1.0\n",
      "Risk of Underfitting: Training accuracy is lower than testing accuracy.\n",
      "\n",
      "Results for NaiveBayes:\n",
      "Training Accuracy: 0.9805499999999998\n",
      "Testing Accuracy: 0.9814\n",
      "Risk of Underfitting: Training accuracy is lower than testing accuracy.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to check overfitting or underfitting\n",
    "def check_overfitting(model_name, model, X_train, y_train, X_test, y_test, cv=5):\n",
    "    # Calculate training accuracy using cross-validation\n",
    "    train_accuracy = np.mean(cross_val_score(model, X_train, y_train, cv=cv))\n",
    "    \n",
    "    # Fit the model to the entire training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate testing accuracy\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    test_accuracy = model.score(X_test, y_test_encoded)\n",
    "    \n",
    "    print(f\"\\nResults for {model_name}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracy}\")\n",
    "    print(f\"Testing Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    # Compare training and testing accuracy\n",
    "    if train_accuracy > test_accuracy:\n",
    "        print(\"Risk of Overfitting: Training accuracy is higher than testing accuracy.\")\n",
    "    elif train_accuracy < test_accuracy:\n",
    "        print(\"Risk of Underfitting: Training accuracy is lower than testing accuracy.\")\n",
    "\n",
    "# Example usage for all models\n",
    "for model_name, model in models.items():\n",
    "    check_overfitting(model_name, model, X_train, label_encoder.transform(y_train), X_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570ad46",
   "metadata": {},
   "source": [
    "# Tuning and pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d60487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edfc735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8762c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'imputer__strategy': ['mean', 'median'],  # Reduce options for demonstration\n",
    "    'classifier__n_estimators': [50, 100],\n",
    "    'classifier__max_depth': [None, 10],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2],\n",
    "    'classifier__bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7285611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__bootstrap': [True, False],\n",
       "                         'classifier__max_depth': [None, 10],\n",
       "                         'classifier__min_samples_leaf': [1, 2],\n",
       "                         'classifier__min_samples_split': [2, 5],\n",
       "                         'classifier__n_estimators': [50, 100],\n",
       "                         'imputer__strategy': ['mean', 'median']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, label_encoder.transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5e7201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e47c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best = best_model.predict(X_test)\n",
    "accuracy_best = accuracy_score(label_encoder.transform(y_test), y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(label_encoder.transform(y_test), y_pred_best)\n",
    "class_report_best = classification_report(label_encoder.transform(y_test), y_pred_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efe430da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Results:\n",
      "Best Parameters: {'classifier__bootstrap': True, 'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 50, 'imputer__strategy': 'mean'}\n",
      "Best Accuracy: 0.9998\n",
      "Confusion Matrix:\n",
      "[[3889    0]\n",
      " [   1 1110]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3889\n",
      "           1       1.00      1.00      1.00      1111\n",
      "\n",
      "    accuracy                           1.00      5000\n",
      "   macro avg       1.00      1.00      1.00      5000\n",
      "weighted avg       1.00      1.00      1.00      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Model Results:\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Accuracy: {accuracy_best}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix_best}\")\n",
    "print(f\"Classification Report:\\n{class_report_best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8cf93df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model  Testing Accuracy\n",
      "1        DecisionTree              1.00\n",
      "5    GradientBoosting              1.00\n",
      "0        RandomForest              1.00\n",
      "6          NaiveBayes              0.98\n",
      "2  LogisticRegression              0.95\n",
      "4                 KNN              0.82\n",
      "3                 SVM              0.78\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=['Model', 'Testing Accuracy'])\n",
    "\n",
    "# Function to check overfitting or underfitting\n",
    "def check_overfitting(model_name, model, X_train, y_train, X_test, y_test, cv=5):\n",
    "    # Calculate training accuracy using cross-validation\n",
    "    train_accuracy = np.mean(cross_val_score(model, X_train, y_train, cv=cv))\n",
    "    \n",
    "    # Fit the model to the entire training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate testing accuracy\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    test_accuracy = model.score(X_test, y_test_encoded)\n",
    "    \n",
    "    # Append results to the DataFrame\n",
    "    results_df.loc[len(results_df)] = [model_name, test_accuracy]\n",
    "\n",
    "# Example usage for all models\n",
    "for model_name, model in models.items():\n",
    "    check_overfitting(model_name, model, X_train, label_encoder.transform(y_train), X_test, y_test)\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_df.sort_values(by='Testing Accuracy', ascending=False, inplace=True)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee803efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
